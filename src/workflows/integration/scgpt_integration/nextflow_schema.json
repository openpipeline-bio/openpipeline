{
"$schema": "http://json-schema.org/draft-07/schema",
"title": "scgpt_integration",
"description": "Generation of cell embeddings for the integration of transcriptomics data using scGPT.",
"type": "object",
"definitions": {

    
    "Dataset input": {
        "title": "Dataset input",
        "type": "object",
        "description": "Dataset input using nf-tower \"dataset\" or \"data explorer\". Allows for the input of multiple         parameter sets to initialise a Nextflow channel.",
        "properties": {
            "param_list": {
                "description": "Dataset input can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml                 blob. The names of the input fields (e.g. csv columns, json keys) need to be an exact match with the workflow input parameters.",
                "default": "",
                "format": "file-path",
                "mimetype": "text/csv",
                "pattern": "^\\S+\\.csv$"
            }
        }
    },

    
    
    "outputs" : {
    "title": "Outputs",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "output": {
                "type":
                "string",
                "description": "Type: `file`, required, default: `$id.$key.output.h5mu`, example: `output.h5mu`. Destination path to the output",
                "help_text": "Type: `file`, required, default: `$id.$key.output.h5mu`, example: `output.h5mu`. Destination path to the output."
            ,
                "default": "$id.$key.output.h5mu"
            }
    

        ,
                "output_compression": {
                "type":
                "string",
                "description": "Type: `string`, example: `gzip`, choices: ``gzip`, `lzf``. The compression algorithm to use for the output h5mu file",
                "help_text": "Type: `string`, example: `gzip`, choices: ``gzip`, `lzf``. The compression algorithm to use for the output h5mu file.\n",
                "enum": ["gzip", "lzf"]
            
            
            }
    

}
},
    
    
    "input" : {
    "title": "Input",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "id": {
                "type":
                "string",
                "description": "Type: `string`, required, example: `foo`. ID of the sample",
                "help_text": "Type: `string`, required, example: `foo`. ID of the sample."
            
            }
    

        ,
                "input": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `input.h5mu`. Path to the sample",
                "help_text": "Type: `file`, required, example: `input.h5mu`. Path to the sample."
            
            }
    

        ,
                "modality": {
                "type":
                "string",
                "description": "Type: `string`, default: `rna`. ",
                "help_text": "Type: `string`, default: `rna`. "
            ,
                "default": "rna"
            }
    

        ,
                "model": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `resources_test/scgpt/best_model.pt`. Path to scGPT model file",
                "help_text": "Type: `file`, required, example: `resources_test/scgpt/best_model.pt`. Path to scGPT model file.\n"
            
            }
    

        ,
                "model_vocab": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `resources_test/scgpt/vocab.json`. Path to scGPT model vocabulary file",
                "help_text": "Type: `file`, required, example: `resources_test/scgpt/vocab.json`. Path to scGPT model vocabulary file.\n"
            
            }
    

        ,
                "model_config": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `args.json`. Path to scGPT model config file",
                "help_text": "Type: `file`, required, example: `args.json`. Path to scGPT model config file.\n"
            
            }
    

        ,
                "input_layer": {
                "type":
                "string",
                "description": "Type: `string`. Mudata layer (key from ",
                "help_text": "Type: `string`. Mudata layer (key from .layers) to use as input data for binning. If not specified, .X is used.\n"
            
            }
    

        ,
                "var_gene_names": {
                "type":
                "string",
                "description": "Type: `string`. The name of the adata",
                "help_text": "Type: `string`. The name of the adata.var column containing gene names. When no gene_name_layer is provided, the var index will be used.\n"
            
            }
    

        ,
                "obs_batch_label": {
                "type":
                "string",
                "description": "Type: `string`. The name of the adata",
                "help_text": "Type: `string`. The name of the adata.obs column containing the batch labels.\n"
            
            }
    

}
},
    
    
    "scgpt integration options" : {
    "title": "scGPT integration options",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "binned_layer": {
                "type":
                "string",
                "description": "Type: `string`, default: `binned`. The name of the adata layer to write the binned data to",
                "help_text": "Type: `string`, default: `binned`. The name of the adata layer to write the binned data to.\n"
            ,
                "default": "binned"
            }
    

        ,
                "obsm_embeddings": {
                "type":
                "string",
                "description": "Type: `string`, default: `X_scGPT`. The name of the adata",
                "help_text": "Type: `string`, default: `X_scGPT`. The name of the adata.obsm array to which scGPT embeddings will be written.\n"
            ,
                "default": "X_scGPT"
            }
    

        ,
                "obsm_gene_tokens": {
                "type":
                "string",
                "description": "Type: `string`, default: `gene_id_tokens`, example: `values.pt`. The key of the obsm array containing the gene token ids\n",
                "help_text": "Type: `string`, default: `gene_id_tokens`, example: `values.pt`. The key of the obsm array containing the gene token ids\n"
            ,
                "default": "gene_id_tokens"
            }
    

        ,
                "obsm_tokenized_values": {
                "type":
                "string",
                "description": "Type: `string`, default: `values_tokenized`. The key of the obsm array containing the count values of the tokenized genes\n",
                "help_text": "Type: `string`, default: `values_tokenized`. The key of the obsm array containing the count values of the tokenized genes\n"
            ,
                "default": "values_tokenized"
            }
    

        ,
                "obsm_padding_mask": {
                "type":
                "string",
                "description": "Type: `string`, default: `padding_mask`. The key of the obsm array containing the padding mask",
                "help_text": "Type: `string`, default: `padding_mask`. The key of the obsm array containing the padding mask.\n"
            ,
                "default": "padding_mask"
            }
    

        ,
                "pad_token": {
                "type":
                "string",
                "description": "Type: `string`, default: `\u003cpad\u003e`. The padding token used in the model",
                "help_text": "Type: `string`, default: `\u003cpad\u003e`. The padding token used in the model.\n"
            ,
                "default": "<pad>"
            }
    

        ,
                "pad_value": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `-2`. The value of the padding token",
                "help_text": "Type: `integer`, default: `-2`. The value of the padding token.\n"
            ,
                "default": "-2"
            }
    

        ,
                "n_input_bins": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `51`. The number of bins to discretize the data into",
                "help_text": "Type: `integer`, default: `51`. The number of bins to discretize the data into. When no value is provided, data won\u0027t be binned.\n"
            ,
                "default": "51"
            }
    

        ,
                "n_hvg": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `1200`. Number of highly variable genes to subset for",
                "help_text": "Type: `integer`, default: `1200`. Number of highly variable genes to subset for.\n"
            ,
                "default": "1200"
            }
    

        ,
                "max_seq_len": {
                "type":
                "integer",
                "description": "Type: `integer`. The maximum sequence length of the tokenized data",
                "help_text": "Type: `integer`. The maximum sequence length of the tokenized data.\n"
            
            }
    

        ,
                "dropout": {
                "type":
                "number",
                "description": "Type: `double`, default: `0.2`. Dropout value used for the transformer encoder layer\n",
                "help_text": "Type: `double`, default: `0.2`. Dropout value used for the transformer encoder layer\n"
            ,
                "default": "0.2"
            }
    

        ,
                "DSBN": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. Apply domain-specific batch normalization\n",
                "help_text": "Type: `boolean`, default: `true`. Apply domain-specific batch normalization\n"
            ,
                "default": "True"
            }
    

        ,
                "batch_size": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `64`. The batch size to be used for inference \n",
                "help_text": "Type: `integer`, default: `64`. The batch size to be used for inference \n"
            ,
                "default": "64"
            }
    

}
},
    
    
    "neighbors and umap options" : {
    "title": "Neighbors and UMAP options",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "uns_neighbors": {
                "type":
                "string",
                "description": "Type: `string`, default: `scGPT_integration_neighbors`. In which uns slot to store various neighbor output objects",
                "help_text": "Type: `string`, default: `scGPT_integration_neighbors`. In which uns slot to store various neighbor output objects."
            ,
                "default": "scGPT_integration_neighbors"
            }
    

        ,
                "obsp_neighbor_distances": {
                "type":
                "string",
                "description": "Type: `string`, default: `scGPT_integration_distances`. In which obsp slot to store the distance matrix between the resulting neighbors",
                "help_text": "Type: `string`, default: `scGPT_integration_distances`. In which obsp slot to store the distance matrix between the resulting neighbors."
            ,
                "default": "scGPT_integration_distances"
            }
    

        ,
                "obsp_neighbor_connectivities": {
                "type":
                "string",
                "description": "Type: `string`, default: `scGPT_integration_connectivities`. In which obsp slot to store the connectivities matrix between the resulting neighbors",
                "help_text": "Type: `string`, default: `scGPT_integration_connectivities`. In which obsp slot to store the connectivities matrix between the resulting neighbors."
            ,
                "default": "scGPT_integration_connectivities"
            }
    

        ,
                "obsm_umap": {
                "type":
                "string",
                "description": "Type: `string`, default: `X_scGPT_umap`. In which ",
                "help_text": "Type: `string`, default: `X_scGPT_umap`. In which .obsm slot to store the resulting UMAP embedding."
            ,
                "default": "X_scGPT_umap"
            }
    

}
},
    
    
    "nextflow input-output arguments" : {
    "title": "Nextflow input-output arguments",
    "type": "object",
    "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
    "properties": {
    
        
                "publish_dir": {
                "type":
                "string",
                "description": "Type: `string`, required, example: `output/`. Path to an output directory",
                "help_text": "Type: `string`, required, example: `output/`. Path to an output directory."
            
            }
    

        

}
}
},
"allOf": [

    {
    "$ref": "#/definitions/outputs"
    },

    {
    "$ref": "#/definitions/input"
    },

    {
    "$ref": "#/definitions/scgpt integration options"
    },

    {
    "$ref": "#/definitions/neighbors and umap options"
    },

    {
    "$ref": "#/definitions/nextflow input-output arguments"
    }
]
}
