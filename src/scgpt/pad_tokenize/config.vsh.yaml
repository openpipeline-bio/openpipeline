functionality:
  name: pad_tokenize
  namespace: "scgpt"
  description: |
    Tokenize and pad a batch of data for scGPT inference or training.
  authors:
    - __merge__: /src/authors/dorien_roosen.yaml
      roles: [ maintainer, author ]

  argument_groups:
    - name: Inputs
      arguments:
        - name: "--input"
          type: file
          direction: input
          required: true
          example: input.h5ad
          description: |
            The input h5mu file containing of pre-processed data.
        - name: "--model_dir"
          type: file
          direction: input
          required: true
          example: foundational_model/scgpt
          description: |
            The directory containing the model files. Must contain 'vocab.json', 'model.pt' and 'args.json' files.
        - name: "--input_layer"
          type: string
          example: "X_binned"
          required: false
          description: |
            The name of the layer to be padded and tokenized.
        - name: "--gene_name_layer"
          type: string
          example: "gene_name"
          required: false
          description: |
            The name of the layer containing gene names.

    - name: Outputs
      arguments:
        - name: "--output_gene_ids"
          type: file
          required: true
          description: |
            The output pytorch tensor file containing the gene ids.
          direction: output
          example: gene_ids.pt
        - name: "--output_values"
          type: file
          required: true
          direction: output
          description: |
            The output pytorch tensor file contianing the tokenized and padded values.
          example: values.pt
        - name: "--output_padding_mask"
          type: file
          direction: output
          required: true
          example: padding_mask.pt
          description: |
            The output pytorch tensor file containing the padding mask.

    - name: Arguments
      arguments:
        - name: "--pad_token"
          type: string
          default: "<pad>"
          required: false
          description: |
            The name of the layer to be padded and tokenized
        - name: "--pad_value"
          type: integer
          default: -2
          required: false
          description: |
            The value to be used for padding.
        - name: "--n_hvg"
          type: integer
          default: 1200
          required: false
          description: |
            The number of highly variable genes to be used for tokenization.  
        - name: "--load_model_vocab"
          type: boolean_true
          description: |
            Whether to load the vocabulary from the model or use pytorch vocab.

  resources:
    - type: python_script
      path: script.py

platforms:
  - type: docker
    image: python:3.10
    setup:
      - type: apt
        packages: 
          - procps
          - gfortran
          - cmake
          - libopenblas-dev
      - type: python
        __merge__: /src/base/requirements/anndata_mudata.yaml
      - type: python
        packages:
          - torch
          - numpy
          - scipy
          - scgpt==0.2.1
          - ipython
  - type: nextflow
