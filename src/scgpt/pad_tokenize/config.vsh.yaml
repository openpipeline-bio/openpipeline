functionality:
  name: pad_tokenize
  namespace: "scgpt"
  description: |
    Tokenize and pad a batch of data for scGPT integration zero-shot inference or fine-tuning.
  authors:
    - __merge__: /src/authors/dorien_roosen.yaml
      roles: [ maintainer, author ]

  argument_groups:
    - name: Inputs
      arguments:
        - name: "--input"
          type: file
          direction: input
          required: true
          example: input.h5mu
          description: |
            The input h5mu file of pre-processed data.
        - name: "--modality"
          type: string
          default: "rna"
          required: false
        - name: "--model_vocab"
          type: file
          direction: input
          required: true
          example: vocab.json
          description: |
            Path to model vocabulary file.
        - name: "--input_layer"
          type: string
          default: "binned"
          required: false
          description: |
            The name of the layer to be padded and tokenized.
        - name: "--input_var_gene_names"
          type: string
          required: false
          description: |
            The name of the .var column containing gene names. When no gene_name_layer is provided, the .var index will be used.

    - name: Outputs
      arguments:
        - name: "--output"
          type: file
          required: true
          description: |
            The output h5mu file containing obsm arrays for gene tokens, tokenized data and padding mask.
          direction: output
          example: output.h5mu
        - name: "--output_compression"
          type: string
          example: "gzip"
          choices: ["gzip", "lzf"]
          description: |
            The compression type for the output file.
        - name: "--output_obsm_gene_tokens"
          type: string
          default: "gene_id_tokens"
          description: |
            The key of the .obsm array containing the gene token ids
          example: values.pt
        - name: "--output_obsm_tokenized_values"
          type: string
          default: values_tokenized
          description: |
            The key of the .obsm array containing the count values of the tokenized genes
        - name: "--output_obsm_padding_mask"
          type: string
          default: padding_mask
          description: |
            The key of the .obsm array containing the padding mask.

    - name: Arguments
      arguments:
        - name: "--pad_token"
          type: string
          default: "<pad>"
          required: false
          description: |
            Token used for padding.
        - name: "--pad_value"
          type: integer
          default: -2
          required: false
          description: |
            The value of the padding token.
        - name: "--max_seq_len"
          type: integer
          required: false
          description: |
            The maximum sequence length of the tokenized data.

  resources:
    - type: python_script
      path: script.py
  test_resources:
    - type: python_script
      path: test.py
    - path: /resources_test/scgpt/

platforms:
  - type: docker
    image: nvcr.io/nvidia/pytorch:23.09-py3
    setup:
      - type: python
        __merge__: [ /src/base/requirements/anndata_mudata.yaml, /src/base/requirements/scanpy.yaml ]
      - type: python
        packages:
          - scgpt==0.2.1
          - ipython~=8.5.0
    test_setup:
      - type: python
        __merge__: [ /src/base/requirements/viashpy.yaml ]
  - type: nextflow
