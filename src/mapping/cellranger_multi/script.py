from __future__ import annotations

import os
import re
import subprocess
import tempfile
import logging
from sys import stdout
import pandas as pd
from typing import TypeVar, Optional, Any, Union, Iterable

logger = logging.getLogger()
logger.setLevel(logging.INFO)
console_handler = logging.StreamHandler(stdout)
logFormatter = logging.Formatter("%(asctime)s %(levelname)-8s %(message)s")
console_handler.setFormatter(logFormatter)
logger.addHandler(console_handler)

## VIASH START
# The following code has been auto-generated by Viash.
par = {
  'output': '/path/to/output',
  'input': 'mysample_S1_L001_R1_001.fastq.gz;mysample_S1_L001_R2_001.fastq.gz'.split(';'),
  'gex_reference': 'reference_genome.tar.gz',
  'vdj_reference': 'reference_vdj.tar.gz',
  'feature_reference': 'feature_reference.csv',
  'library_id': 'mysample'.split(';'),
  'library_type': 'Gene Expression'.split(';'),
  'library_subsample': list(map(float, '0.5'.split(';'))),
  'gex_expect_cells': int('3000'),
  'gex_chemistry': 'auto',
  'gex_ssecondary_analysis': 'false'.lower() == 'true',
  'gex_generate_bam': 'true'.lower() == 'true',
  'gex_include_introns': 'true'.lower() == 'true',
  'cell_multiplex_sample_id': 'value',
  'cell_multiplex_oligo_ids': 'value',
  'cell_multiplex_description': 'value'
}
meta = {
  'n_proc': None,
  'memory_b': None,
  'memory_kb': None,
  'memory_mb': None,
  'memory_gb': None,
  'memory_tb': None,
  'memory_pb': None
}
## VIASH END

fastq_regex = r'([A-Za-z0-9\-_\.]+)_S(\d+)_L(\d+)_R(\d+)_(\d+)\.fastq\.gz'
# assert re.match(fastq_regex, "5k_human_GEX_1_subset_S1_L001_R1_001.fastq.gz") is not None

dic = {'foo': [1, 2], 'bar': [3, 1, 2], 'zing': [1], 'lift': None}
output = {'foo': 2, 'bar': 3}

# assert lengths_gt1({'foo': [1, 2], 'bar': [3, 1, 2], 'zing': [1], 'lift': None}) == {'foo': 2, 'bar': 3}
def lengths_gt1(dic: dict[str, Optional[list[Any]]]) -> dict[str, int]:
  #def lengths_gt1(dic):
  return { key: len(li) for key, li in dic.items() if li is not None and len(li) > 1 }
  
def strip_margin(text: str) -> str:
  return re.sub('(\n?)[ \t]*\|', '\\1', text)

T = TypeVar('T')

def subset_dict(dictionary: dict[str, T], keys: Union[dict[str, str], list[str]]) -> dict[str, T]:
  if isinstance(keys, list):
    keys = { key: key for key in keys }
  return { dest_key: dictionary[orig_key] for dest_key, orig_key in keys.items() if dictionary[orig_key] is not None }

def check_subset_dict_equal_length(group_name: str, dictionary: dict[str, list[T]]) -> None:
  lens = lengths_gt1(dictionary)
  assert len(set(lens.values())) <= 1, f"The number of values passed to {group_name} arguments must be 0, 1 or all the same. Offenders: {lens}"

def process_params(par: dict[str, Any]) -> str:
  # if par_input is a directory, look for fastq files
  if len(par["input"]) == 1 and os.path.isdir(par["input"][0]):
    logger.info("Detected '--input' as a directory, traversing to see if we can detect any FASTQ files.")
    par["input"] = [ os.path.join(dp, f) for dp, _, filenames in os.walk(par["input"]) for f in filenames if re.match(fastq_regex, f) ]

  # check input fastq files
  for input in par["input"]:
    assert re.match(fastq_regex, os.path.basename(input)) is not None, f"File name of --input '{input}' should match regex {fastq_regex}."
  
  # check lengths of libraries metadata 
  library_dict = subset_dict(par, ["library_id", "library_type", "library_subsample"])
  check_subset_dict_equal_length("Library", library_dict)
  # storing for later use
  par["libraries"] = library_dict

  cmo_dict = subset_dict(par, ["cell_multiplex_sample_id", "cell_multiplex_oligo_ids", "cell_multiplex_description"])
  check_subset_dict_equal_length("Cell multiplexing", cmo_dict)
  # storing for later use
  par["cmo"] = cmo_dict

  # use absolute paths
  par["input"] = [ os.path.abspath(f) for f in par["input"] ]
  if par["gex_reference"]:
    par["gex_reference"] = os.path.abspath(par["gex_reference"])
  if par["vdj_reference"]:
    par["vdj_reference"] = os.path.abspath(par["vdj_reference"])
  if par["feature_reference"]:
    par["feature_reference"] = os.path.abspath(par["feature_reference"])
  par["output"] = os.path.abspath(par["output"])
  
  return par

# assert generate_csv_category('abc',{'foo': None}) == []
# assert generate_csv_category('abc',{'foo': None, 'bar': 'xxx'}) == ['[abc]', 'bar,xxx', '']
# assert generate_csv_category('def',{'foo': 'yyy', 'bar': 'xxx'}) == ['[def]', 'foo,yyy', 'bar,xxx', '']
def generate_dict_category(name: str, args: dict[str, str]) -> list[str]:
  title = [ f'[{name}]' ]
  values = [ f'{key},{val}' for key, val in args.items() if val is not None ]
  if len(values) > 0:
    return title + values + [""]
  else:
    return []

def generate_csv_category(name: str, args: dict[str, str]) -> list[str]:
  title = [ f'[{name}]' ]
  if len(args) > 0:
    values = [ pd.DataFrame(args).to_csv(index=False) ]
    return title + values + [""]
  else:
    return []


def generate_config(par: dict[str, Any], fastq_dir: str) -> str:
  # process gene expression parameters
  gex_pars = subset_dict(par, {'ref': 'gex_reference'})
  gex_strs = generate_dict_category('gene-expression', gex_pars)

  # process vdj parameters
  vdj_pars = subset_dict(par, {'ref': 'vdj_reference'})
  vdj_strs = generate_dict_category('vdj', vdj_pars)

  # process feature parameters
  feature_pars = subset_dict(par, {'ref': 'feature_reference'})
  feature_strs = generate_dict_category('feature', feature_pars)

  # process libraries parameters
  library_pars = subset_dict(par, {'fastq_id': 'library_id', 'feature_types': 'library_type', 'subsample_rate': 'library_subsample'})
  library_pars['fastqs'] = fastq_dir
  libraries_strs = generate_csv_category("libraries", library_pars)

  # process samples parameters
  cmo_pars = subset_dict(par, {'sample_id': 'cell_multiplex_sample_id', 'cmo_ids': 'cell_multiplex_oligo_ids', 'description': 'cell_multiplex_description'})
  cmo_strs = generate_csv_category("samples", cmo_pars)
  
  # combine content
  content_list = gex_strs + vdj_strs + feature_strs + libraries_strs + cmo_strs
  return '\n'.join(content_list)

def main(par: dict[str, Any], meta: dict[str, Any]):
  logger.info("  Processing params")
  par = process_params(par)
  print(par)

  # TODO: throw error or else Cell Ranger will
  # # Create output dir if not exists

  with tempfile.TemporaryDirectory(prefix="cellranger_multi-", dir=meta["temp_dir"]) as temp_dir:
    logger.info("  Creating config file")
    config_content = generate_config(par, temp_dir)

    logger.info("  Creating Cell Ranger argument")
    temp_id = "run"
    proc_pars = ["--disable-ui", "--id", temp_id]

    if meta["n_proc"]:
      proc_pars.append(f"--localcores={meta['meta_n_proc']}")

    if meta["memory_gb"]:
      proc_pars.append(f"--localmem={int(meta['memory_gb']) - 2}")

    ## Run pipeline

    if par["dryrun"]:
      cmd = ["cellranger multi"] + proc_pars + ["--csv=config.csv"]
      logger.info("> " + ' '.join(cmd))
      print()
      print("Contents of 'config.csv':")
      print(config_content)
    else:
      # write config file
      config_file = os.path.join(temp_dir, "config.csv")
      with open(config_file, "w") as f:
        f.write(config_content)
      proc_pars.append(f"--csv={config_file}")

      # create symlinks to data

      # run process
      cmd = ["cellranger multi"] + proc_pars
      logger.info("> " + ' '.join(cmd))
      _ = subprocess.check_call(
        cmd,
        cwd=temp_dir
      )

      # look for output dir file
      tmp_output_dir = os.path.join(temp_dir, temp_id, "outs")
      expected_files = {
        "multi": "directory", 
        "per_sample_outs": "directory", 
        "config.csv": "file",
      }
      for file, type in expected_files.items():
        path = os.path.join(tmp_output_dir, file)
        if not os.path.exists(path):
          raise ValueError(f"Could not find expected {type} '{path}'")

if __name__ == "__main__":
    main(par, meta)

