{
"$schema": "http://json-schema.org/draft-07/schema",
"title": "integration_embedding",
"description": "Embedding of a batch of data for scGPT zero-shot or fine-tuning integration.\n",
"type": "object",
"definitions": {

    
    "Dataset input": {
        "title": "Dataset input",
        "type": "object",
        "description": "Dataset input using nf-tower \"dataset\" or \"data explorer\". Allows for the input of multiple         parameter sets to initialise a Nextflow channel.",
        "properties": {
            "param_list": {
                "description": "Dataset input can either be a list of maps, a csv file, a json file, a yaml file, or simply a yaml                 blob. The names of the input fields (e.g. csv columns, json keys) need to be an exact match with the workflow input parameters.",
                "default": "",
                "format": "file-path",
                "mimetype": "text/csv",
                "pattern": "^\\S+\\.csv$"
            }
        }
    },

    
    
    "inputs" : {
    "title": "Inputs",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "input": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `input.h5ad`. The input h5mu file containing of pre-processed data",
                "help_text": "Type: `file`, required, example: `input.h5ad`. The input h5mu file containing of pre-processed data. \n"
            
            }
    

        ,
                "model_dir": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `foundational_model/scgpt`. The directory containing the model files",
                "help_text": "Type: `file`, required, example: `foundational_model/scgpt`. The directory containing the model files. Must contain \u0027vocab.json\u0027, \u0027model.pt\u0027 and \u0027args.json\u0027 files.\n"
            
            }
    

        ,
                "input_gene_ids": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `gene_ids.pt`. Path to pytorch tensor file containing the gene ids",
                "help_text": "Type: `file`, required, example: `gene_ids.pt`. Path to pytorch tensor file containing the gene ids.\n"
            
            }
    

        ,
                "input_values": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `values.pt`. Path to pytorch tensor file containing the tokenized and padded values",
                "help_text": "Type: `file`, required, example: `values.pt`. Path to pytorch tensor file containing the tokenized and padded values.\n"
            
            }
    

        ,
                "input_padding_mask": {
                "type":
                "string",
                "description": "Type: `file`, required, example: `padding_mask.pt`. Path to pytorch tensor file containing the padding mask",
                "help_text": "Type: `file`, required, example: `padding_mask.pt`. Path to pytorch tensor file containing the padding mask.\n"
            
            }
    

        ,
                "gene_name_layer": {
                "type":
                "string",
                "description": "Type: `string`, default: `gene_name`. The name of adata",
                "help_text": "Type: `string`, default: `gene_name`. The name of adata.var column containing gene names.\n"
            ,
                "default": "gene_name"
            }
    

        ,
                "batch_id_layer": {
                "type":
                "string",
                "description": "Type: `string`, default: `batch_id`. The name of the adata",
                "help_text": "Type: `string`, default: `batch_id`. The name of the adata.obs column containing the batch ids.\n"
            ,
                "default": "batch_id"
            }
    

}
},
    
    
    "outputs" : {
    "title": "Outputs",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "output": {
                "type":
                "string",
                "description": "Type: `file`, required, default: `$id.$key.output.h5ad`, example: `output.h5ad`. Path to output anndata file containing pre-processed data as well as scGPT embeddings",
                "help_text": "Type: `file`, required, default: `$id.$key.output.h5ad`, example: `output.h5ad`. Path to output anndata file containing pre-processed data as well as scGPT embeddings.\n"
            ,
                "default": "$id.$key.output.h5ad"
            }
    

        ,
                "embedding_layer": {
                "type":
                "string",
                "description": "Type: `string`, default: `X_scGPT`. The name of the adata",
                "help_text": "Type: `string`, default: `X_scGPT`. The name of the adata.obsm array to which scGPT embeddings will be written.\n"
            ,
                "default": "X_scGPT"
            }
    

}
},
    
    
    "arguments" : {
    "title": "Arguments",
    "type": "object",
    "description": "No description",
    "properties": {
    
        
                "pad_token": {
                "type":
                "string",
                "description": "Type: `string`, default: `\u003cpad\u003e`. The name of the layer to be padded and tokenized\n",
                "help_text": "Type: `string`, default: `\u003cpad\u003e`. The name of the layer to be padded and tokenized\n"
            ,
                "default": "<pad>"
            }
    

        ,
                "pad_value": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `-2`. The value to be used for padding",
                "help_text": "Type: `integer`, default: `-2`. The value to be used for padding.\n"
            ,
                "default": "-2"
            }
    

        ,
                "load_model_vocab": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. Whether to load the vocabulary from the model or use pytorch vocab",
                "help_text": "Type: `boolean`, default: `true`. Whether to load the vocabulary from the model or use pytorch vocab.\n"
            ,
                "default": "True"
            }
    

        ,
                "load_model_configs": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. Whether to load the configs from the model",
                "help_text": "Type: `boolean`, default: `true`. Whether to load the configs from the model.\n"
            ,
                "default": "True"
            }
    

        ,
                "layer_size": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `128`. ",
                "help_text": "Type: `integer`, default: `128`. "
            ,
                "default": "128"
            }
    

        ,
                "nhead": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `4`. ",
                "help_text": "Type: `integer`, default: `4`. "
            ,
                "default": "4"
            }
    

        ,
                "nlayers": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `4`. ",
                "help_text": "Type: `integer`, default: `4`. "
            ,
                "default": "4"
            }
    

        ,
                "dropout": {
                "type":
                "number",
                "description": "Type: `double`, default: `0.2`. ",
                "help_text": "Type: `double`, default: `0.2`. "
            ,
                "default": "0.2"
            }
    

        ,
                "DSBN": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. Domain-specific batch normalization\n",
                "help_text": "Type: `boolean`, default: `true`. Domain-specific batch normalization\n"
            ,
                "default": "True"
            }
    

        ,
                "GEPC": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. Gene Expression modeling for Cell objective\n",
                "help_text": "Type: `boolean`, default: `true`. Gene Expression modeling for Cell objective\n"
            ,
                "default": "True"
            }
    

        ,
                "n_input_bins": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `51`. ",
                "help_text": "Type: `integer`, default: `51`. "
            ,
                "default": "51"
            }
    

        ,
                "ecs_threshold": {
                "type":
                "number",
                "description": "Type: `double`, default: `0.8`. ",
                "help_text": "Type: `double`, default: `0.8`. "
            ,
                "default": "0.8"
            }
    

        ,
                "explicit_zero_prob": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `true`. ",
                "help_text": "Type: `boolean`, default: `true`. "
            ,
                "default": "True"
            }
    

        ,
                "use_fast_transformer": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `false`. ",
                "help_text": "Type: `boolean`, default: `false`. "
            ,
                "default": "False"
            }
    

        ,
                "pre_norm": {
                "type":
                "boolean",
                "description": "Type: `boolean`, default: `false`. ",
                "help_text": "Type: `boolean`, default: `false`. "
            ,
                "default": "False"
            }
    

        ,
                "device": {
                "type":
                "string",
                "description": "Type: `string`, default: `cpu`, choices: ``cpu`, `cuda``. Whether to generate embeddings using cpu or gpu (cuda) device",
                "help_text": "Type: `string`, default: `cpu`, choices: ``cpu`, `cuda``. Whether to generate embeddings using cpu or gpu (cuda) device.\n",
                "enum": ["cpu", "cuda"]
            
            ,
                "default": "cpu"
            }
    

        ,
                "batch_size": {
                "type":
                "integer",
                "description": "Type: `integer`, default: `64`. ",
                "help_text": "Type: `integer`, default: `64`. "
            ,
                "default": "64"
            }
    

}
},
    
    
    "nextflow input-output arguments" : {
    "title": "Nextflow input-output arguments",
    "type": "object",
    "description": "Input/output parameters for Nextflow itself. Please note that both publishDir and publish_dir are supported but at least one has to be configured.",
    "properties": {
    
        
                "publish_dir": {
                "type":
                "string",
                "description": "Type: `string`, required, example: `output/`. Path to an output directory",
                "help_text": "Type: `string`, required, example: `output/`. Path to an output directory."
            
            }
    

        

}
}
},
"allOf": [

    {
    "$ref": "#/definitions/inputs"
    },

    {
    "$ref": "#/definitions/outputs"
    },

    {
    "$ref": "#/definitions/arguments"
    },

    {
    "$ref": "#/definitions/nextflow input-output arguments"
    }
]
}
